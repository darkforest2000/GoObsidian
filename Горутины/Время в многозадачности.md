### Обработка с ожиданием

Есть у нас некоторая полезная работа, которую приходится выполнять в больших количествах:

```go
work := func() {
    // что-то очень нужное, но не очень быстрое
    time.Sleep(100 * time.Millisecond)
}
```

Проще всего — обрабатывать последовательно:

```go
func main() {
    work := func() {
        time.Sleep(100 * time.Millisecond)
    }

    start := time.Now()

    work()
    work()
    work()
    work()

    fmt.Println("4 calls took", time.Since(start))
}
```

```bash
4 calls took 400ms
```

Четыре вызова по 100 мс каждый выполнились последовательно за 400 мс.

Конечно, быстрее выполнять работу параллельно, в N «обработчиков». Тогда логика будет такой:

-   если есть свободный обработчик — отдать запрос ему;
-   иначе ждать, пока кто-нибудь освободится.

На шаге про [N обработчиков](https://stepik.org/lesson/740355/step/6?unit=742025) мы уже решали похожую задачу. Вспомним принцип:

-   создаем канал с буфером размера N и заполняем его «токенами» (любыми значениями);
-   перед запуском обработчика забираем токен из канала;
-   по завершении обработчика возвращаем токен в канал.

Сделаем обертку `withWorkers(n, fn)`, которая обеспечивает одновременное выполнение. Для этого заведем канал `free` и будем следить, чтобы запускались не более `n` функций `fn()` одновременно:

```go
func withWorkers(n int, fn func()) (handle func(), wait func()) {
    // канал с токенами
    free := make(chan struct{}, n)
    for i := 0; i < n; i++ {
        free <- struct{}{}
    }

    // выполняет fn, но не более n одновременно
    handle = func() {
        <-free
        go func() {
            fn()
            free <- struct{}{}
        }()
    }

    // ожидает, пока все запущенные fn отработают
    wait = func() {
        for i := 0; i < n; i++ {
            <-free
        }
    }

    return handle, wait
}
```

Теперь клиент вызывает функцию `work()` не напрямую, а через обертку:

```go
func main() {
    work := func() {
        time.Sleep(100 * time.Millisecond)
    }

    handle, wait := withWorkers(2, work)

    start := time.Now()

    handle()
    handle()
    handle()
    handle()
    wait()

    fmt.Println("4 calls took", time.Since(start))
}
```

```bash
4 calls took 200ms
```

Получилось так:

-   первый и второй вызовы сразу пошли в обработку;
-   третий и четвертый ждали, пока предыдущие два закончат обрабатываться.

В результате при двух обработчиках 4 вызова выполняются за 200 мс.

Схема обработки с ожиданием отлично подходит, когда степень параллелизма `n` и индивидуальное время работы `work()` примерно соответствуют интенсивности, с которой вызывают `handle()`. Тогда у каждого вызова есть хороший шанс сразу пойти в обработку.

Если же вызовов сильно больше, чем способны «прожевать» обработчики — система начнет «тормозить». Каждый отдельный `work()` по-прежнему будет отрабатывать за 100 мс. Но вызовы `handle()` будут подвисать, ведь каждому придется ждать свободного токена. Для обработки данных в конвейере это не страшно, а вот для онлайн-запросов может быть не слишком хорошо.

Бывает, что клиент предпочел бы сразу получить ошибку в ответ на `handle()`, если все обработчики заняты. Тут схема с ожиданием уже не подойдет.

[песочница](https://go.dev/play/p/ytr0HV3sM4n)


### Обработка без ожидания

Изменим логику `withWorkers()`:

-   если есть свободный токен — выполнить функцию;
-   иначе сразу вернуть ошибку.

Так клиенту не придется ждать «подвисшего» вызова.

Нам в очередной раз поможет инструкция `select`:

```go
// выполняет fn, но не более n одновременно
handle = func() error {
    select {
    case <-free:
        go func() {
            fn()
            free <- struct{}{}
        }()
        return nil
    default:
        return errors.New("busy")
    }
}
```

Вспомним алгоритм работы селекта:

1.  Проверяет, какие ветки не заблокированы.
2.  Если таких веток несколько, выбирает одну из них случайным образом и выполняет ее.
3.  Если все ветки заблокированы, блокирует выполнение, пока хотя бы одна ветка не разблокируется.

На самом деле, третий пункт разбивается на два:

-   Если все ветки заблокированы _и нет блока default_ — блокирует выполнение, пока хотя бы одна ветка не разблокируется.
-   Если все ветки заблокированы _и есть блок default_ — выполняет его.

`default` идеально подходит для нашей ситуации:

-   если есть свободный токен в канале `free` — запускаем `fn`;
-   иначе ничего не ждем и возвращаем ошибку `busy`.

Посмотрим на клиента:

```go
func main() {
    work := func() {
        time.Sleep(100 * time.Millisecond)
    }

    handle, wait := withWorkers(2, work)

    start := time.Now()

    err := handle()
    fmt.Println("1st call, error:", err)

    err = handle()
    fmt.Println("2nd call, error:", err)

    err = handle()
    fmt.Println("3rd call, error:", err)

    err = handle()
    fmt.Println("4th call, error:", err)

    wait()

    fmt.Println("4 calls took", time.Since(start))
}
```

```bash
1st call, error: <nil>
2nd call, error: <nil>
3rd call, error: busy
4th call, error: busy
4 calls took 100ms
```

Первые два вызова выполнились одновременно (по 100 мс каждый), а третий и четвертый моментально получили ошибку. В итоге все вызовы обработались за 100 мс.

Конечно, при таком подходе требуется некоторая «сознательность» клиента. Клиент должен понять, что ошибка «busy» означает перегруз, и отложить дальнейшие вызовы `handle()` на некоторое время, или уменьшить их частоту.

[песочница](https://go.dev/play/p/dlNG7BWs-vP)